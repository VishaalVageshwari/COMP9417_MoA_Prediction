{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf61195",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-20T16:51:58.770590Z",
     "iopub.status.busy": "2021-07-20T16:51:58.769988Z",
     "iopub.status.idle": "2021-07-20T16:51:58.801890Z",
     "shell.execute_reply": "2021-07-20T16:51:58.801355Z",
     "shell.execute_reply.started": "2021-07-20T15:42:29.848784Z"
    },
    "papermill": {
     "duration": 0.053544,
     "end_time": "2021-07-20T16:51:58.802029",
     "exception": false,
     "start_time": "2021-07-20T16:51:58.748485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ba5005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:51:58.822702Z",
     "iopub.status.busy": "2021-07-20T16:51:58.822090Z",
     "iopub.status.idle": "2021-07-20T16:52:00.885730Z",
     "shell.execute_reply": "2021-07-20T16:52:00.885159Z",
     "shell.execute_reply.started": "2021-07-20T16:35:21.846691Z"
    },
    "papermill": {
     "duration": 2.075573,
     "end_time": "2021-07-20T16:52:00.885896",
     "exception": false,
     "start_time": "2021-07-20T16:51:58.810323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2763668c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:00.909692Z",
     "iopub.status.busy": "2021-07-20T16:52:00.908945Z",
     "iopub.status.idle": "2021-07-20T16:52:00.911669Z",
     "shell.execute_reply": "2021-07-20T16:52:00.911256Z",
     "shell.execute_reply.started": "2021-07-20T15:45:00.743053Z"
    },
    "papermill": {
     "duration": 0.016745,
     "end_time": "2021-07-20T16:52:00.911779",
     "exception": false,
     "start_time": "2021-07-20T16:52:00.895034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2,\n",
    "                 output_size, dropout=0.2):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0683dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:00.934281Z",
     "iopub.status.busy": "2021-07-20T16:52:00.933563Z",
     "iopub.status.idle": "2021-07-20T16:52:00.936218Z",
     "shell.execute_reply": "2021-07-20T16:52:00.935824Z",
     "shell.execute_reply.started": "2021-07-20T15:45:15.688805Z"
    },
    "papermill": {
     "duration": 0.017164,
     "end_time": "2021-07-20T16:52:00.936367",
     "exception": false,
     "start_time": "2021-07-20T16:52:00.919203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.values\n",
    "        self.targets = targets.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx_features = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        idx_targets = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return idx_features, idx_targets\n",
    "\n",
    "\n",
    "class TestMoADataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx_features = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        return idx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd1a658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:00.955658Z",
     "iopub.status.busy": "2021-07-20T16:52:00.954959Z",
     "iopub.status.idle": "2021-07-20T16:52:00.957352Z",
     "shell.execute_reply": "2021-07-20T16:52:00.957810Z",
     "shell.execute_reply.started": "2021-07-20T15:58:11.754949Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2021-07-20T16:52:00.957927",
     "exception": false,
     "start_time": "2021-07-20T16:52:00.943826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed, use_cuda=False):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3022d9ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:00.983529Z",
     "iopub.status.busy": "2021-07-20T16:52:00.982607Z",
     "iopub.status.idle": "2021-07-20T16:52:00.985388Z",
     "shell.execute_reply": "2021-07-20T16:52:00.984905Z",
     "shell.execute_reply.started": "2021-07-20T15:46:00.541202Z"
    },
    "papermill": {
     "duration": 0.020002,
     "end_time": "2021-07-20T16:52:00.985522",
     "exception": false,
     "start_time": "2021-07-20T16:52:00.965520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['cp_type'] = df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72:2})\n",
    "    df = df.drop('sig_id', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(dir):\n",
    "    X_train = pd.read_csv(f'{dir}/train_features.csv')\n",
    "    Y_train = pd.read_csv(f'{dir}/train_targets_scored.csv')\n",
    "    X_test = pd.read_csv(f'{dir}/test_features.csv')\n",
    "    ss = pd.read_csv(f'{dir}/sample_submission.csv')\n",
    "\n",
    "    train = X_train.merge(Y_train, on='sig_id')\n",
    "    X_train = train.loc[:, X_train.columns]\n",
    "    Y_train = train.loc[:, Y_train.columns]\n",
    "\n",
    "    X_train = preprocess(X_train)\n",
    "    X_test = preprocess(X_test)\n",
    "\n",
    "    Y_train = Y_train.drop('sig_id', axis=1)\n",
    "\n",
    "    return X_train, Y_train, X_test, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d7346c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:01.118594Z",
     "iopub.status.busy": "2021-07-20T16:52:01.104831Z",
     "iopub.status.idle": "2021-07-20T16:52:01.120643Z",
     "shell.execute_reply": "2021-07-20T16:52:01.121025Z",
     "shell.execute_reply.started": "2021-07-20T16:02:37.668016Z"
    },
    "papermill": {
     "duration": 0.126734,
     "end_time": "2021-07-20T16:52:01.121176",
     "exception": false,
     "start_time": "2021-07-20T16:52:00.994442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 2048\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "SEED = 42\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "\n",
    "def train_fun(model, optimizer, loss_fun, train_loader, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fun(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "        #     print(f'Train Epoch: {epoch + 1}, Batch: [{(batch_idx + 1)}/{len(train_loader)}], Loss: {loss.item():.3f}')\n",
    "\n",
    "    mean_loss = running_loss / len(train_loader)\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "def validate_fun(model, loss_fun, val_loader, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fun(outputs, targets)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # if (batch_idx + 1) % 1024 == 0 or (batch_idx + 1) == len(val_loader):\n",
    "        #     print(f'Validate Epoch: {epoch + 1}, Batch: [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.6f}')\n",
    "\n",
    "    mean_loss = running_loss / len(val_loader)\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "def test_fun(model, test_loader, device):\n",
    "    Y_pred_lst = []\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, inputs in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        Y_pred_lst.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    Y_pred = np.concatenate(Y_pred_lst)\n",
    "\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def train_simple_net(fold, X_test, train_loader, val_loader, in_size, out_size, device):\n",
    "    model = SimpleNet(in_size, 2048, 1024, out_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fun = nn.BCEWithLogitsLoss()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_train_loss = train_fun(model, optimizer, loss_fun, train_loader, device, epoch)\n",
    "        epoch_val_loss = validate_fun(model, loss_fun, val_loader, device, epoch)\n",
    "\n",
    "        # print(f'Epoch: {epoch}, Train Loss: {epoch_train_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "        if epoch_val_loss < best_loss:\n",
    "            best_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), f'simple_fold_{fold + 1}.pth')\n",
    "    \n",
    "        test_dataset = TestMoADataset(X_test)   \n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = SimpleNet(in_size, 2048, 1024, out_size).to(device)\n",
    "    model.load_state_dict(torch.load(f'simple_fold_{fold + 1}.pth'))\n",
    "    model.to(device)\n",
    "\n",
    "    Y_pred = test_fun(model, test_loader, device)\n",
    "\n",
    "    return best_loss, Y_pred\n",
    "\n",
    "\n",
    "def run_msk_fold_cv(X_train, Y_train, X_test, num_folds, model_name, device):\n",
    "    running_loss = 0\n",
    "    Y_pred = np.zeros((X_test.shape[0], Y_train.shape[1]))\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, shuffle=False, random_state=None)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(mskf.split(X_train, Y_train)):\n",
    "        fold_X_train = X_train.loc[trn_idx, :]\n",
    "        fold_Y_train = Y_train.loc[trn_idx, :]\n",
    "        fold_X_val = X_train.loc[val_idx, :]\n",
    "        fold_Y_val = Y_train.loc[val_idx, :]\n",
    "\n",
    "        train_dataset = MoADataset(fold_X_train, fold_Y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        val_dataset = MoADataset(fold_X_val, fold_Y_val)   \n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        print(f'Fold: {fold + 1}')\n",
    "\n",
    "        if model_name == 'simple':\n",
    "            fold_loss, fold_Y_pred = train_simple_net(fold, X_test, train_loader, val_loader, X_train.shape[1], Y_train.shape[1], device)\n",
    "            Y_pred += fold_Y_pred\n",
    "            running_loss += fold_loss\n",
    "\n",
    "    Y_pred /= num_folds\n",
    "    cv_loss = running_loss / num_folds\n",
    "\n",
    "    print(f'CV loss: {cv_loss:.6f}')\n",
    "\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def run_simple_net(mode):\n",
    "    use_cuda = False\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    Y_pred = None\n",
    "\n",
    "    if device == ('cuda'):\n",
    "        use_cuda = True\n",
    "\n",
    "    seed_everything(SEED, use_cuda)\n",
    "\n",
    "    X_train, Y_train, X_test, ss = prepare_data('../input/lish-moa')\n",
    "\n",
    "    if mode == 'cv':\n",
    "        Y_pred = run_msk_fold_cv(X_train, Y_train, X_test, NUM_FOLDS, 'simple', device)\n",
    "\n",
    "    ss.iloc[:, 1:] = Y_pred\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e72c874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:52:01.179146Z",
     "iopub.status.busy": "2021-07-20T16:52:01.178194Z",
     "iopub.status.idle": "2021-07-20T16:54:55.681356Z",
     "shell.execute_reply": "2021-07-20T16:54:55.680904Z",
     "shell.execute_reply.started": "2021-07-20T16:02:42.379787Z"
    },
    "papermill": {
     "duration": 174.552455,
     "end_time": "2021-07-20T16:54:55.681505",
     "exception": false,
     "start_time": "2021-07-20T16:52:01.129050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "Fold: 5\n",
      "CV loss: 0.015839\n"
     ]
    }
   ],
   "source": [
    "sub = run_simple_net('cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e617ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T16:54:55.704797Z",
     "iopub.status.busy": "2021-07-20T16:54:55.704139Z",
     "iopub.status.idle": "2021-07-20T16:54:57.329898Z",
     "shell.execute_reply": "2021-07-20T16:54:57.329008Z",
     "shell.execute_reply.started": "2021-07-20T16:19:21.72033Z"
    },
    "papermill": {
     "duration": 1.639069,
     "end_time": "2021-07-20T16:54:57.330040",
     "exception": false,
     "start_time": "2021-07-20T16:54:55.690971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.710738,
   "end_time": "2021-07-20T16:54:59.701306",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-20T16:51:51.990568",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
