{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7fa691",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-31T08:07:54.900833Z",
     "iopub.status.busy": "2021-07-31T08:07:54.890376Z",
     "iopub.status.idle": "2021-07-31T08:08:30.222026Z",
     "shell.execute_reply": "2021-07-31T08:08:30.221054Z",
     "shell.execute_reply.started": "2021-07-31T07:52:49.965474Z"
    },
    "papermill": {
     "duration": 35.352772,
     "end_time": "2021-07-31T08:08:30.222194",
     "exception": false,
     "start_time": "2021-07-31T08:07:54.869422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.3)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.19.5)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.61.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.6)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-3.1.1\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Processing /kaggle/input/iterative-stratification/iterative-stratification-master\r\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\r\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.19.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.6.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.23.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Building wheels for collected packages: iterative-stratification\r\n",
      "  Building wheel for iterative-stratification (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iterative-stratification: filename=iterative_stratification-0.1.6-py3-none-any.whl size=8401 sha256=35f44c8b437941c54d8f534d939c31f405d2422466d96642b8dc0efb7e7111ee\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/47/3f/eb4af42d124f37d23d6f13a4c8bbc32c1d70140e6e1cecb4aa\r\n",
      "Successfully built iterative-stratification\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl pytorch-tabnet\n",
    "!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2b1c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:30.251640Z",
     "iopub.status.busy": "2021-07-31T08:08:30.251045Z",
     "iopub.status.idle": "2021-07-31T08:08:30.286023Z",
     "shell.execute_reply": "2021-07-31T08:08:30.286797Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.769554Z"
    },
    "papermill": {
     "duration": 0.052162,
     "end_time": "2021-07-31T08:08:30.287025",
     "exception": false,
     "start_time": "2021-07-31T08:08:30.234863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-3.1.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.1-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-1.2.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-3.0.0-py3-none-any.whl\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bf4d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:30.346818Z",
     "iopub.status.busy": "2021-07-31T08:08:30.346036Z",
     "iopub.status.idle": "2021-07-31T08:08:32.359267Z",
     "shell.execute_reply": "2021-07-31T08:08:32.358818Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.792072Z"
    },
    "papermill": {
     "duration": 2.04994,
     "end_time": "2021-07-31T08:08:32.359388",
     "exception": false,
     "start_time": "2021-07-31T08:08:30.309448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import log_loss\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912b901b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.389576Z",
     "iopub.status.busy": "2021-07-31T08:08:32.388664Z",
     "iopub.status.idle": "2021-07-31T08:08:32.391266Z",
     "shell.execute_reply": "2021-07-31T08:08:32.390873Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.802817Z"
    },
    "papermill": {
     "duration": 0.019374,
     "end_time": "2021-07-31T08:08:32.391370",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.371996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = 'logits_ll'\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        aux = (1 - y_true) * np.log(1 - expit(y_pred) + 1e-15) + y_true * np.log(expit(y_pred) + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe2d91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.420495Z",
     "iopub.status.busy": "2021-07-31T08:08:32.419827Z",
     "iopub.status.idle": "2021-07-31T08:08:32.422472Z",
     "shell.execute_reply": "2021-07-31T08:08:32.422069Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.812487Z"
    },
    "papermill": {
     "duration": 0.019015,
     "end_time": "2021-07-31T08:08:32.422586",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.403571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed, use_cuda=False):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9767a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.454959Z",
     "iopub.status.busy": "2021-07-31T08:08:32.454264Z",
     "iopub.status.idle": "2021-07-31T08:08:32.457026Z",
     "shell.execute_reply": "2021-07-31T08:08:32.456607Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.821079Z"
    },
    "papermill": {
     "duration": 0.022041,
     "end_time": "2021-07-31T08:08:32.457121",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.435080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72:2})\n",
    "    df = df[df['cp_type']  != 'ctl_vehicle'].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(dir):\n",
    "    X_train = pd.read_csv(f'{dir}/train_features.csv')\n",
    "    Y_train = pd.read_csv(f'{dir}/train_targets_scored.csv')\n",
    "    X_test = pd.read_csv(f'{dir}/test_features.csv')\n",
    "    ss = pd.read_csv(f'{dir}/sample_submission.csv')\n",
    "\n",
    "    train = X_train.merge(Y_train, on='sig_id')\n",
    "    Y_train_stub = train.loc[:, Y_train.columns]\n",
    "    \n",
    "    train = preprocess(train)\n",
    "    X_test = preprocess(X_test).drop(['cp_type'], axis=1)\n",
    "\n",
    "    X_train = train.loc[:, X_train.columns].drop(['sig_id', 'cp_type'], axis=1)\n",
    "    Y_train = train.loc[:, Y_train.columns]\n",
    "\n",
    "    return X_train, Y_train, Y_train_stub, X_test, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd6737b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.484694Z",
     "iopub.status.busy": "2021-07-31T08:08:32.484030Z",
     "iopub.status.idle": "2021-07-31T08:08:32.486458Z",
     "shell.execute_reply": "2021-07-31T08:08:32.486891Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.836043Z"
    },
    "papermill": {
     "duration": 0.017849,
     "end_time": "2021-07-31T08:08:32.487001",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.469152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 2e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "SEED = 42\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8057f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.618179Z",
     "iopub.status.busy": "2021-07-31T08:08:32.616512Z",
     "iopub.status.idle": "2021-07-31T08:08:32.618798Z",
     "shell.execute_reply": "2021-07-31T08:08:32.619189Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.845937Z"
    },
    "papermill": {
     "duration": 0.120185,
     "end_time": "2021-07-31T08:08:32.619332",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.499147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_tab_net(fold, X_test, X_train, Y_train, X_val, Y_val, train_size, val_idx, out_size):\n",
    "    oof = np.zeros((train_size, out_size))\n",
    "    tabnet_params = dict(\n",
    "                        n_d=32,\n",
    "                        n_a=32,\n",
    "                        n_steps=1,\n",
    "                        gamma=1.8,\n",
    "                        lambda_sparse=0,\n",
    "                        optimizer_fn=torch.optim.Adam,\n",
    "                        optimizer_params=dict(lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY),\n",
    "                        scheduler_params=dict(mode='min',\n",
    "                                              patience=5,\n",
    "                                              min_lr=1e-5,\n",
    "                                              factor=0.9),\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                        mask_type='entmax',\n",
    "                        seed=SEED,\n",
    "                        verbose=10\n",
    "                    )\n",
    "\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, \n",
    "        y_train=Y_train,\n",
    "        eval_set = [(X_val, Y_val)],\n",
    "        eval_name=['val'],\n",
    "        eval_metric=[LogitsLogLoss],\n",
    "        max_epochs=EPOCHS,\n",
    "        patience=20,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        virtual_batch_size=128,\n",
    "        num_workers=1,\n",
    "        drop_last=False,\n",
    "        loss_fn=nn.BCEWithLogitsLoss()\n",
    "    )\n",
    "\n",
    "    oof[val_idx] = expit(model.predict(X_val))\n",
    "    Y_pred = expit(model.predict(X_test))\n",
    "\n",
    "    return np.min(model.history['val_logits_ll']), Y_pred, oof\n",
    "\n",
    "def run_msk_fold_cv(X_train, Y_train, Y_train_stub, X_test, ss, num_folds, device):\n",
    "    running_loss = 0\n",
    "    Y_pred = np.zeros((X_test.shape[0], Y_train.shape[1] - 1))\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "    oof = np.zeros((X_train.shape[0], Y_train.shape[1] - 1))\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(mskf.split(X_train, Y_train)):\n",
    "        fold_X_train = X_train.loc[trn_idx, :].to_numpy()\n",
    "        fold_Y_train = Y_train.loc[trn_idx, :].drop('sig_id', axis=1).to_numpy()\n",
    "        fold_X_val = X_train.loc[val_idx, :].to_numpy()\n",
    "        fold_Y_val = Y_train.loc[val_idx, :].drop('sig_id', axis=1).to_numpy()\n",
    "        \n",
    "        print(f'Fold: {fold + 1}')\n",
    "\n",
    "        fold_loss, fold_Y_pred, fold_oof = train_tab_net(fold, X_test.drop('sig_id', axis=1).to_numpy(), \n",
    "                                                         fold_X_train, fold_Y_train,\n",
    "                                                         fold_X_val, fold_Y_val,\n",
    "                                                         X_train.shape[0], val_idx, \n",
    "                                                         Y_train.shape[1] - 1)\n",
    "        \n",
    "        Y_pred += fold_Y_pred\n",
    "        oof += fold_oof\n",
    "        running_loss += fold_loss\n",
    "        \n",
    "    Y_pred /= num_folds\n",
    "    oof /= num_folds\n",
    "    cv_loss = running_loss / num_folds\n",
    "\n",
    "    oof_Y_pred = Y_train.copy()\n",
    "    oof_Y_pred.iloc[:, 1:] = oof\n",
    "    oof_Y_pred = Y_train_stub.loc[:, ['sig_id']].merge(oof_Y_pred, on='sig_id', how='left').fillna(0)\n",
    "\n",
    "    Y_true = Y_train_stub.iloc[:, 1:].values\n",
    "    oof_Y_pred = oof_Y_pred.iloc[:, 1:].values\n",
    "\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(oof_Y_pred.shape[1]):\n",
    "        cv_score += log_loss(Y_true[:, i], oof_Y_pred[:, i])\n",
    "\n",
    "    cv_score /= oof_Y_pred.shape[1]\n",
    "\n",
    "    print(f'CV loss (ctl_vechile excluded): {cv_loss:.6f}')\n",
    "    print(f'CV loss: {cv_score:.6f}')\n",
    "\n",
    "    test_Y_pred = X_test.loc[:, ['sig_id']].merge(ss, how='left', on=['sig_id'])\n",
    "    test_Y_pred.iloc[:, 1:] = Y_pred\n",
    "    test_Y_pred = ss.loc[:, ['sig_id']].merge(test_Y_pred, on='sig_id', how='left').fillna(0)\n",
    "\n",
    "    return test_Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0058b656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.650046Z",
     "iopub.status.busy": "2021-07-31T08:08:32.648522Z",
     "iopub.status.idle": "2021-07-31T08:08:32.650827Z",
     "shell.execute_reply": "2021-07-31T08:08:32.651219Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.868219Z"
    },
    "papermill": {
     "duration": 0.019423,
     "end_time": "2021-07-31T08:08:32.651344",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.631921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_net():\n",
    "    use_cuda = False\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    Y_pred = None\n",
    "\n",
    "    if device == ('cuda'):\n",
    "        use_cuda = True\n",
    "\n",
    "    seed_everything(SEED, use_cuda)\n",
    "\n",
    "    X_train, Y_train, Y_train_stub, X_test, ss = prepare_data('../input/lish-moa')\n",
    "\n",
    "    Y_pred = run_msk_fold_cv(X_train, Y_train, Y_train_stub, X_test, ss, NUM_FOLDS, device)\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa70a9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:08:32.718604Z",
     "iopub.status.busy": "2021-07-31T08:08:32.717997Z",
     "iopub.status.idle": "2021-07-31T08:18:10.392280Z",
     "shell.execute_reply": "2021-07-31T08:18:10.391800Z",
     "shell.execute_reply.started": "2021-07-31T07:53:23.882775Z"
    },
    "papermill": {
     "duration": 577.729218,
     "end_time": "2021-07-31T08:18:10.392416",
     "exception": false,
     "start_time": "2021-07-31T08:08:32.663198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3576  | val_logits_ll: 0.04619 |  0:00:02s\n",
      "epoch 10 | loss: 0.01994 | val_logits_ll: 0.01992 |  0:00:13s\n",
      "epoch 20 | loss: 0.01767 | val_logits_ll: 0.01782 |  0:00:24s\n",
      "epoch 30 | loss: 0.01677 | val_logits_ll: 0.0175  |  0:00:36s\n",
      "epoch 40 | loss: 0.01636 | val_logits_ll: 0.01804 |  0:00:46s\n",
      "epoch 50 | loss: 0.01597 | val_logits_ll: 0.01728 |  0:00:58s\n",
      "epoch 60 | loss: 0.01586 | val_logits_ll: 0.01698 |  0:01:10s\n",
      "epoch 70 | loss: 0.01549 | val_logits_ll: 0.017   |  0:01:21s\n",
      "epoch 80 | loss: 0.01501 | val_logits_ll: 0.01747 |  0:01:32s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 62 and best_val_logits_ll = 0.01683\n",
      "Best weights from best epoch are automatically used!\n",
      "Fold: 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36189 | val_logits_ll: 0.04236 |  0:00:01s\n",
      "epoch 10 | loss: 0.01957 | val_logits_ll: 0.01972 |  0:00:12s\n",
      "epoch 20 | loss: 0.0175  | val_logits_ll: 0.0192  |  0:00:23s\n",
      "epoch 30 | loss: 0.01698 | val_logits_ll: 0.01949 |  0:00:35s\n",
      "epoch 40 | loss: 0.01618 | val_logits_ll: 0.01739 |  0:00:46s\n",
      "epoch 50 | loss: 0.01598 | val_logits_ll: 0.01856 |  0:00:58s\n",
      "epoch 60 | loss: 0.01564 | val_logits_ll: 0.01882 |  0:01:09s\n",
      "epoch 70 | loss: 0.01529 | val_logits_ll: 0.01731 |  0:01:21s\n",
      "epoch 80 | loss: 0.01509 | val_logits_ll: 0.01779 |  0:01:32s\n",
      "epoch 90 | loss: 0.01455 | val_logits_ll: 0.01733 |  0:01:44s\n",
      "\n",
      "Early stopping occurred at epoch 98 with best_epoch = 78 and best_val_logits_ll = 0.01718\n",
      "Best weights from best epoch are automatically used!\n",
      "Fold: 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35974 | val_logits_ll: 0.0414  |  0:00:01s\n",
      "epoch 10 | loss: 0.01973 | val_logits_ll: 0.01989 |  0:00:12s\n",
      "epoch 20 | loss: 0.01727 | val_logits_ll: 0.01809 |  0:00:23s\n",
      "epoch 30 | loss: 0.01671 | val_logits_ll: 0.02058 |  0:00:35s\n",
      "epoch 40 | loss: 0.01612 | val_logits_ll: 0.01892 |  0:00:46s\n",
      "epoch 50 | loss: 0.01614 | val_logits_ll: 0.01787 |  0:00:57s\n",
      "epoch 60 | loss: 0.01567 | val_logits_ll: 0.01726 |  0:01:08s\n",
      "epoch 70 | loss: 0.0154  | val_logits_ll: 0.01714 |  0:01:20s\n",
      "epoch 80 | loss: 0.01491 | val_logits_ll: 0.01714 |  0:01:32s\n",
      "epoch 90 | loss: 0.01489 | val_logits_ll: 0.01732 |  0:01:43s\n",
      "\n",
      "Early stopping occurred at epoch 95 with best_epoch = 75 and best_val_logits_ll = 0.017\n",
      "Best weights from best epoch are automatically used!\n",
      "Fold: 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36608 | val_logits_ll: 0.04519 |  0:00:01s\n",
      "epoch 10 | loss: 0.01959 | val_logits_ll: 0.01968 |  0:00:12s\n",
      "epoch 20 | loss: 0.01756 | val_logits_ll: 0.01804 |  0:00:23s\n",
      "epoch 30 | loss: 0.01687 | val_logits_ll: 0.0177  |  0:00:34s\n",
      "epoch 40 | loss: 0.01622 | val_logits_ll: 0.01929 |  0:00:46s\n",
      "epoch 50 | loss: 0.01599 | val_logits_ll: 0.01712 |  0:00:58s\n",
      "epoch 60 | loss: 0.01603 | val_logits_ll: 0.01738 |  0:01:08s\n",
      "epoch 70 | loss: 0.0158  | val_logits_ll: 0.01695 |  0:01:20s\n",
      "epoch 80 | loss: 0.01571 | val_logits_ll: 0.01703 |  0:01:31s\n",
      "epoch 90 | loss: 0.01556 | val_logits_ll: 0.01714 |  0:01:42s\n",
      "epoch 100| loss: 0.01538 | val_logits_ll: 0.01717 |  0:01:54s\n",
      "epoch 110| loss: 0.01528 | val_logits_ll: 0.01712 |  0:02:05s\n",
      "\n",
      "Early stopping occurred at epoch 112 with best_epoch = 92 and best_val_logits_ll = 0.01687\n",
      "Best weights from best epoch are automatically used!\n",
      "Fold: 5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3659  | val_logits_ll: 0.04331 |  0:00:01s\n",
      "epoch 10 | loss: 0.01982 | val_logits_ll: 0.0199  |  0:00:12s\n",
      "epoch 20 | loss: 0.01751 | val_logits_ll: 0.01871 |  0:00:23s\n",
      "epoch 30 | loss: 0.01664 | val_logits_ll: 0.01736 |  0:00:34s\n",
      "epoch 40 | loss: 0.01639 | val_logits_ll: 0.01738 |  0:00:46s\n",
      "epoch 50 | loss: 0.01632 | val_logits_ll: 0.01749 |  0:00:57s\n",
      "epoch 60 | loss: 0.01569 | val_logits_ll: 0.01721 |  0:01:08s\n",
      "epoch 70 | loss: 0.01546 | val_logits_ll: 0.0171  |  0:01:20s\n",
      "epoch 80 | loss: 0.01544 | val_logits_ll: 0.01781 |  0:01:32s\n",
      "epoch 90 | loss: 0.0149  | val_logits_ll: 0.01717 |  0:01:43s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 74 and best_val_logits_ll = 0.01696\n",
      "Best weights from best epoch are automatically used!\n",
      "CV loss (ctl_vechile excluded): 0.016967\n",
      "CV loss: 0.018854\n"
     ]
    }
   ],
   "source": [
    "sub = run_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0aa7887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T08:18:10.453294Z",
     "iopub.status.busy": "2021-07-31T08:18:10.452694Z",
     "iopub.status.idle": "2021-07-31T08:18:11.955995Z",
     "shell.execute_reply": "2021-07-31T08:18:11.955479Z",
     "shell.execute_reply.started": "2021-07-31T08:03:04.388185Z"
    },
    "papermill": {
     "duration": 1.535288,
     "end_time": "2021-07-31T08:18:11.956125",
     "exception": false,
     "start_time": "2021-07-31T08:18:10.420837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 625.769073,
   "end_time": "2021-07-31T08:18:13.921422",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-31T08:07:48.152349",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
